{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to fine tune the XGBoost model and perform evaulation on user data for 7 day Free Trial.\n",
    "\n",
    "The whole process has been divided into 2 notebooks: \n",
    "\n",
    "- Part 1: Data Preprocessing: 6.0_sk_fine_tuning_FT_propensity_data_preprocessing.ipynb (this notebook)\n",
    "- part 2: Data Modeling and Evaluation: 6.0_sk_fine_tuning_FT_propensity_data_modeling.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=101\n",
    "SMALL_DATASET=False\n",
    "\n",
    "BUCKET = \"datascience-hbo-users\"\n",
    "PREFIX = \"users/sk/FT_propensity/7_day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session(default_bucket=BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.r5.24xlarge',\n",
    "                                     output_kms_key='alias/aws/s3',\n",
    "                                     instance_count=1,\n",
    "                                     sagemaker_session=sagemaker_session,\n",
    "                                     base_job_name='FT-Propensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "output_destination = 's3://datascience-hbo-users/users/sk/FT_propensity/7_day/model_input_data'\n",
    "input_source = 's3://datascience-hbo-users/users/sk/FT_propensity/7_day/snowflake-hbomax-staging'\n",
    "\n",
    "sklearn_processor.run(code='preprocessing.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=input_source,\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[\n",
    "                               ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train',\n",
    "                                                destination=output_destination),\n",
    "                               \n",
    "                               ProcessingOutput(output_name='test_data',\n",
    "                                                source='/opt/ml/processing/test',\n",
    "                                                destination=output_destination),\n",
    "                          \n",
    "                               ProcessingOutput(output_name='val_data',\n",
    "                                               source='/opt/ml/processing/val',\n",
    "                                               destination=output_destination)\n",
    "                               \n",
    "                               \n",
    "                              ],\n",
    "                      arguments=['--train-test-split-ratio', '0.1']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
