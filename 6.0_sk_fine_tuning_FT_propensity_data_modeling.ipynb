{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to fine tune the XGBoost model and perform evaulation on user data for 7 day Free Trial.\n",
    "\n",
    "The whole process has been divided into 2 notebooks: \n",
    "\n",
    "- Part 1: Data Preprocessing: 6.0_sk_fine_tuning_FT_propensity_data_preprocessing.ipynb \n",
    "- part 2: Data Modeling and Evaluation: 6.0_sk_fine_tuning_FT_propensity_data_modeling.ipynb (this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             total       used       free     shared    buffers     cached\r\n",
      "Mem:         70342      39816      30526          0        936       8534\r\n",
      "-/+ buffers/cache:      30345      39997\r\n",
      "Swap:            0          0          0\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "import sagemaker.xgboost as xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=101\n",
    "SMALL_DATASET=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL=\"FLG_TARGET\"\n",
    "SEGMENT_COL=\"FT_SEGMENT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"datascience-hbo-users\"\n",
    "PREFIX = \"users/sk/FT_propensity/7_day\"\n",
    "DATA_PREFIX=PREFIX+\"/model_input_data\"\n",
    "MODEL_PREFIX=PREFIX+\"/model_artifacts\"\n",
    "INFERENCE_PREFIX=PREFIX+\"/inference\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Processing/Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check of S3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "train_file_name=\"train.csv\"\n",
    "test_file_name=\"test.csv\"\n",
    "val_file_name=\"val.csv\"\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(BUCKET, DATA_PREFIX, train_file_name), content_type='csv')\n",
    "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(BUCKET, DATA_PREFIX, test_file_name), content_type='csv')\n",
    "s3_input_val = sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(BUCKET, DATA_PREFIX, val_file_name), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL=s3_input_train.config[\"DataSource\"][\"S3DataSource\"][\"S3Uri\"]\n",
    "TEST_DATA_URL=s3_input_test.config[\"DataSource\"][\"S3DataSource\"][\"S3Uri\"]\n",
    "VAL_DATA_URL=s3_input_val.config[\"DataSource\"][\"S3DataSource\"][\"S3Uri\"]\n",
    "\n",
    "# df_train_s3=pd.read_csv(TRAIN_DATA_URL , header=None)\n",
    "#df_test_s3=pd.read_csv(TEST_DATA_URL, header=None)\n",
    "# df_val_s3=pd.read_csv(VAL_DATA_URL, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert not df_train_s3.isnull().sum().any()\n",
    "# assert not df_test_s3.isnull().sum().any()\n",
    "# assert not df_val_s3.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "train_side_info_file_name=\"train_side_info.csv\"\n",
    "test_side_info_file_name=\"test_side_info.csv\"\n",
    "val_side_info_file_name=\"val_side_info.csv\"\n",
    "\n",
    "s3_input_train_side_info = sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(BUCKET, DATA_PREFIX, train_side_info_file_name), content_type='csv')\n",
    "s3_input_test_side_info = sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(BUCKET, DATA_PREFIX, test_side_info_file_name), content_type='csv')\n",
    "s3_input_val_side_info = sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(BUCKET, DATA_PREFIX, val_side_info_file_name), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_SIDE_INFO_URL=s3_input_train_side_info.config[\"DataSource\"][\"S3DataSource\"][\"S3Uri\"]\n",
    "TEST_DATA_SIDE_INFO_URL=s3_input_test_side_info.config[\"DataSource\"][\"S3DataSource\"][\"S3Uri\"]\n",
    "VAL_DATA_SIDE_INFO_URL=s3_input_val_side_info.config[\"DataSource\"][\"S3DataSource\"][\"S3Uri\"]\n",
    "side_info_cols=[\"UNIQUE_ID\", \"HBO_UUID\", \"PERIOD_RANK\", \"FT_SEGMENT\"]\n",
    "# df_train_side_info_s3=pd.read_csv(TRAIN_DATA_SIDE_INFO_URL, names=side_info_cols)\n",
    "df_test_side_info_s3=pd.read_csv(VAL_DATA_SIDE_INFO_URL, names=side_info_cols)\n",
    "df_val_side_info_s3=pd.read_csv(TEST_DATA_SIDE_INFO_URL, names=side_info_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684451, 5)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_side_info_s3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert df_train_s3.shape[1]==df_test_s3.shape[1]\n",
    "# assert df_train_s3.shape[1]==df_val_s3.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_train_s3\n",
    "# del df_test_s3\n",
    "# del df_val_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flag STREAM for NUM_STREAM_ADJ>0\n",
    "# Discuss with Cindy to create more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n"
     ]
    }
   ],
   "source": [
    "region = boto3.Session().region_name\n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "container = get_image_uri(region, 'xgboost', repo_version='latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-15 21:36:12 Starting - Starting the training job...\n",
      "2020-07-15 21:36:16 Starting - Launching requested ML instances......\n",
      "2020-07-15 21:37:30 Starting - Preparing the instances for training.........\n",
      "2020-07-15 21:39:07 Downloading - Downloading input data...............\n",
      "2020-07-15 21:41:34 Training - Downloading the training image..\u001b[33mArguments: train\u001b[0m\n",
      "\u001b[33m[2020-07-15:21:41:55:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[36mArguments: train\u001b[0m\n",
      "\u001b[36m[2020-07-15:21:41:55:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[32mArguments: train\u001b[0m\n",
      "\u001b[35mArguments: train\u001b[0m\n",
      "\u001b[35m[2020-07-15:21:41:55:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[32m[2020-07-15:21:41:56:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-07-15:21:41:56:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[33m[2020-07-15:21:41:58:INFO] Number of hosts: 5, master IP address: 10.2.149.189, host IP address: 10.2.149.194.\u001b[0m\n",
      "\u001b[33m[2020-07-15:21:41:58:INFO] Finished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\u001b[33mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-149-194.ec2.internal.out\u001b[0m\n",
      "\u001b[35m[2020-07-15:21:41:58:INFO] Number of hosts: 5, master IP address: 10.2.149.189, host IP address: 10.2.143.102.\u001b[0m\n",
      "\u001b[35m[2020-07-15:21:41:58:INFO] Finished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\u001b[35mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-143-102.ec2.internal.out\u001b[0m\n",
      "\u001b[36m[2020-07-15:21:41:58:INFO] Number of hosts: 5, master IP address: 10.2.149.189, host IP address: 10.2.187.92.\u001b[0m\n",
      "\u001b[36m[2020-07-15:21:41:58:INFO] Finished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\u001b[36mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-187-92.ec2.internal.out\u001b[0m\n",
      "\u001b[32m[2020-07-15:21:41:58:INFO] Number of hosts: 5, master IP address: 10.2.149.189, host IP address: 10.2.166.238.\u001b[0m\n",
      "\u001b[32m[2020-07-15:21:41:58:INFO] Finished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\u001b[32mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-166-238.ec2.internal.out\u001b[0m\n",
      "\u001b[34m[2020-07-15:21:41:59:INFO] Number of hosts: 5, master IP address: 10.2.149.189, host IP address: 10.2.149.189.\u001b[0m\n",
      "\u001b[34m[2020-07-15:21:41:59:INFO] Finished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\n",
      "2020-07-15 21:41:55 Training - Training image download completed. Training in progress.\u001b[34mstarting namenode, logging to /opt/amazon/hadoop/logs/hadoop--namenode-ip-10-2-149-189.ec2.internal.out\u001b[0m\n",
      "\u001b[33mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-149-194.ec2.internal.out\u001b[0m\n",
      "\u001b[35mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-143-102.ec2.internal.out\u001b[0m\n",
      "\u001b[36mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-187-92.ec2.internal.out\u001b[0m\n",
      "\u001b[32mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-166-238.ec2.internal.out\u001b[0m\n",
      "\u001b[33m[2020-07-15:21:42:04:INFO] File size need to be processed in the node: 1047.38mb. Available memory size in the node: 55926.12mb\u001b[0m\n",
      "\u001b[35m[2020-07-15:21:42:03:INFO] File size need to be processed in the node: 1047.38mb. Available memory size in the node: 55908.45mb\u001b[0m\n",
      "\u001b[36m[2020-07-15:21:42:03:INFO] File size need to be processed in the node: 1047.38mb. Available memory size in the node: 55932.09mb\u001b[0m\n",
      "\u001b[32m[2020-07-15:21:42:03:INFO] File size need to be processed in the node: 1047.38mb. Available memory size in the node: 55921.65mb\u001b[0m\n",
      "\u001b[34mstarting resourcemanager, logging to /opt/amazon/hadoop/logs/yarn--resourcemanager-ip-10-2-149-189.ec2.internal.out\u001b[0m\n",
      "\u001b[34mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-149-189.ec2.internal.out\u001b[0m\n",
      "\u001b[34mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-149-189.ec2.internal.out\u001b[0m\n",
      "\u001b[34m[2020-07-15:21:42:12:INFO] File size need to be processed in the node: 1047.38mb. Available memory size in the node: 55202.0mb\u001b[0m\n",
      "\u001b[34m[2020-07-15:21:42:12:INFO] HTTP server started....\u001b[0m\n",
      "\u001b[34m[2020-07-15:21:42:12:INFO] Memory/core ratio is 7.86\u001b[0m\n",
      "\u001b[34m[2020-07-15:21:42:12:INFO] Yarn setup: number of workers: 5, physical cores per worker: 8, physical memory per worker: 62.9g.\u001b[0m\n",
      "\u001b[34m[2020-07-15:21:42:12:INFO] Yarn job submitted successfully.\u001b[0m\n",
      "\u001b[34m2020-07-15 21:42:12,309 INFO start listen on 10.2.149.189:9091\u001b[0m\n",
      "\u001b[34m/xgboost/dmlc-core/tracker/dmlc_tracker/yarn.py:37: UserWarning: cannot find \"/xgboost/dmlc-core/tracker/dmlc_tracker/../yarn/dmlc-yarn.jar\", I will try to run build\n",
      "  warnings.warn(\"cannot find \\\"%s\\\", I will try to run build\" % YARN_JAR_PATH)\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:37: warning: Signal is internal proprietary API and may be removed in a future release\u001b[0m\n",
      "\u001b[34mimport sun.misc.Signal;\n",
      "               ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:38: warning: SignalHandler is internal proprietary API and may be removed in a future release\u001b[0m\n",
      "\u001b[34mimport sun.misc.SignalHandler;\n",
      "               ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:276: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal intSignal = new Signal(\"INT\");\n",
      "        ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:276: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal intSignal = new Signal(\"INT\");\n",
      "                               ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:277: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal.handle(intSignal, handler);\n",
      "        ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:332: warning: SignalHandler is internal proprietary API and may be removed in a future release\n",
      "    class CtrlCHandler implements SignalHandler{\n",
      "                                  ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:339: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        public void handle(Signal signal){\n",
      "                           ^\u001b[0m\n",
      "\u001b[34mNote: src/main/java/org/apache/hadoop/yarn/dmlc/ApplicationMaster.java uses unchecked or unsafe operations.\u001b[0m\n",
      "\u001b[34mNote: Recompile with -Xlint:unchecked for details.\u001b[0m\n",
      "\u001b[34m7 warnings\u001b[0m\n",
      "\u001b[34m20/07/15 21:42:15 INFO client.RMProxy: Connecting to ResourceManager at algo-1/10.2.149.189:8032\u001b[0m\n",
      "\u001b[34m20/07/15 21:42:15 INFO dmlc.Client: HDFS temp directory do not exist, creating.. /tmp\u001b[0m\n",
      "\u001b[34m20/07/15 21:42:16 INFO dmlc.Client: jobname=DMLC[nworker=5]:python,username=root\u001b[0m\n",
      "\u001b[34m20/07/15 21:42:16 INFO dmlc.Client: Submitting application application_1594849327472_0001\u001b[0m\n",
      "\u001b[34m20/07/15 21:42:17 INFO impl.YarnClientImpl: Submitted application application_1594849327472_0001\u001b[0m\n",
      "\u001b[34m2020-07-15 21:42:25,411 INFO @tracker All of 5 nodes getting started\u001b[0m\n",
      "\u001b[34m2020-07-15 21:42:52,417 INFO [0]#011train-auc:0.881829#011validation-auc:0.880678\u001b[0m\n",
      "\u001b[34m2020-07-15 21:42:57,679 INFO [1]#011train-auc:0.884264#011validation-auc:0.883136\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:02,941 INFO [2]#011train-auc:0.885574#011validation-auc:0.884266\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:08,095 INFO [3]#011train-auc:0.886654#011validation-auc:0.885283\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:13,541 INFO [4]#011train-auc:0.888089#011validation-auc:0.886573\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:18,743 INFO [5]#011train-auc:0.889401#011validation-auc:0.887788\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:24,154 INFO [6]#011train-auc:0.890276#011validation-auc:0.888552\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:29,576 INFO [7]#011train-auc:0.891403#011validation-auc:0.889577\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:34,749 INFO [8]#011train-auc:0.892258#011validation-auc:0.890326\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:40,071 INFO [9]#011train-auc:0.893026#011validation-auc:0.89099\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:45,234 INFO [10]#011train-auc:0.89377#011validation-auc:0.891685\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:50,592 INFO [11]#011train-auc:0.894533#011validation-auc:0.892335\u001b[0m\n",
      "\u001b[34m2020-07-15 21:43:55,783 INFO [12]#011train-auc:0.895285#011validation-auc:0.892959\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:00,926 INFO [13]#011train-auc:0.895827#011validation-auc:0.893434\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-07-15 21:44:06,247 INFO [14]#011train-auc:0.896495#011validation-auc:0.893952\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:11,425 INFO [15]#011train-auc:0.897159#011validation-auc:0.894474\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:16,749 INFO [16]#011train-auc:0.89776#011validation-auc:0.894941\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:22,027 INFO [17]#011train-auc:0.898277#011validation-auc:0.895342\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:27,399 INFO [18]#011train-auc:0.898804#011validation-auc:0.895748\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:32,608 INFO [19]#011train-auc:0.899202#011validation-auc:0.896036\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:37,827 INFO [20]#011train-auc:0.899694#011validation-auc:0.896417\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:42,919 INFO [21]#011train-auc:0.900196#011validation-auc:0.896803\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:48,068 INFO [22]#011train-auc:0.900694#011validation-auc:0.897155\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:53,421 INFO [23]#011train-auc:0.901198#011validation-auc:0.897564\u001b[0m\n",
      "\u001b[34m2020-07-15 21:44:58,840 INFO [24]#011train-auc:0.901712#011validation-auc:0.897941\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:03,943 INFO [25]#011train-auc:0.902254#011validation-auc:0.898363\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:09,202 INFO [26]#011train-auc:0.902706#011validation-auc:0.898677\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:14,129 INFO [27]#011train-auc:0.902946#011validation-auc:0.898871\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:18,962 INFO [28]#011train-auc:0.903224#011validation-auc:0.899109\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:24,273 INFO [29]#011train-auc:0.903797#011validation-auc:0.899552\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:29,707 INFO [30]#011train-auc:0.904151#011validation-auc:0.899753\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:34,826 INFO [31]#011train-auc:0.904466#011validation-auc:0.900016\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:39,785 INFO [32]#011train-auc:0.904754#011validation-auc:0.900219\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:44,709 INFO [33]#011train-auc:0.905076#011validation-auc:0.900457\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:49,765 INFO [34]#011train-auc:0.905448#011validation-auc:0.90073\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:54,793 INFO [35]#011train-auc:0.905736#011validation-auc:0.90091\u001b[0m\n",
      "\u001b[34m2020-07-15 21:45:59,622 INFO [36]#011train-auc:0.905955#011validation-auc:0.901045\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:04,514 INFO [37]#011train-auc:0.906102#011validation-auc:0.901162\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:09,346 INFO [38]#011train-auc:0.906438#011validation-auc:0.901421\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:14,096 INFO [39]#011train-auc:0.906697#011validation-auc:0.901628\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:19,123 INFO [40]#011train-auc:0.906984#011validation-auc:0.901832\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:24,065 INFO [41]#011train-auc:0.907258#011validation-auc:0.902036\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:29,042 INFO [42]#011train-auc:0.90751#011validation-auc:0.902236\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:34,326 INFO [43]#011train-auc:0.907778#011validation-auc:0.902394\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:39,476 INFO [44]#011train-auc:0.908154#011validation-auc:0.902683\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:44,722 INFO [45]#011train-auc:0.908527#011validation-auc:0.902938\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:49,571 INFO [46]#011train-auc:0.908747#011validation-auc:0.903099\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:54,662 INFO [47]#011train-auc:0.908998#011validation-auc:0.903274\u001b[0m\n",
      "\u001b[34m2020-07-15 21:46:59,655 INFO [48]#011train-auc:0.909328#011validation-auc:0.903523\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:04,596 INFO [49]#011train-auc:0.909612#011validation-auc:0.903745\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:09,767 INFO [50]#011train-auc:0.90999#011validation-auc:0.904009\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:14,739 INFO [51]#011train-auc:0.910189#011validation-auc:0.904169\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:19,897 INFO [52]#011train-auc:0.910476#011validation-auc:0.904371\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:25,102 INFO [53]#011train-auc:0.910764#011validation-auc:0.90459\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:30,285 INFO [54]#011train-auc:0.911008#011validation-auc:0.904722\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:35,373 INFO [55]#011train-auc:0.911124#011validation-auc:0.90481\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:40,578 INFO [56]#011train-auc:0.911279#011validation-auc:0.904922\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:45,657 INFO [57]#011train-auc:0.911602#011validation-auc:0.905157\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:50,562 INFO [58]#011train-auc:0.911735#011validation-auc:0.905265\u001b[0m\n",
      "\u001b[34m2020-07-15 21:47:55,781 INFO [59]#011train-auc:0.91197#011validation-auc:0.905443\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:01,145 INFO [60]#011train-auc:0.912272#011validation-auc:0.905618\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:06,391 INFO [61]#011train-auc:0.912602#011validation-auc:0.905861\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:11,298 INFO [62]#011train-auc:0.912705#011validation-auc:0.90593\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:16,307 INFO [63]#011train-auc:0.912923#011validation-auc:0.906082\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:21,081 INFO [64]#011train-auc:0.913098#011validation-auc:0.906211\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:26,272 INFO [65]#011train-auc:0.913303#011validation-auc:0.906375\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:30,839 INFO [66]#011train-auc:0.913402#011validation-auc:0.90644\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:36,077 INFO [67]#011train-auc:0.913664#011validation-auc:0.906605\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:41,258 INFO [68]#011train-auc:0.913968#011validation-auc:0.906811\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:46,226 INFO [69]#011train-auc:0.91419#011validation-auc:0.906992\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:51,215 INFO [70]#011train-auc:0.914372#011validation-auc:0.907121\u001b[0m\n",
      "\u001b[34m2020-07-15 21:48:56,315 INFO [71]#011train-auc:0.914693#011validation-auc:0.907322\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:01,391 INFO [72]#011train-auc:0.914873#011validation-auc:0.90745\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:06,167 INFO [73]#011train-auc:0.914979#011validation-auc:0.907522\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:10,604 INFO [74]#011train-auc:0.915045#011validation-auc:0.907568\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:15,147 INFO [75]#011train-auc:0.915131#011validation-auc:0.907642\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:20,222 INFO [76]#011train-auc:0.915373#011validation-auc:0.907789\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:25,197 INFO [77]#011train-auc:0.915651#011validation-auc:0.907981\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:30,325 INFO [78]#011train-auc:0.91594#011validation-auc:0.908173\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:35,592 INFO [79]#011train-auc:0.916229#011validation-auc:0.908357\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:40,153 INFO [80]#011train-auc:0.916314#011validation-auc:0.908422\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:45,148 INFO [81]#011train-auc:0.916587#011validation-auc:0.908598\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:50,085 INFO [82]#011train-auc:0.916724#011validation-auc:0.908686\u001b[0m\n",
      "\u001b[34m2020-07-15 21:49:55,081 INFO [83]#011train-auc:0.916936#011validation-auc:0.90881\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:00,253 INFO [84]#011train-auc:0.917182#011validation-auc:0.908981\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:05,258 INFO [85]#011train-auc:0.91734#011validation-auc:0.909117\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:10,340 INFO [86]#011train-auc:0.917469#011validation-auc:0.909205\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:15,379 INFO [87]#011train-auc:0.91764#011validation-auc:0.909335\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:19,878 INFO [88]#011train-auc:0.917712#011validation-auc:0.909386\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:24,785 INFO [89]#011train-auc:0.917862#011validation-auc:0.909506\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:29,349 INFO [90]#011train-auc:0.917934#011validation-auc:0.909552\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:34,059 INFO [91]#011train-auc:0.918024#011validation-auc:0.909616\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:38,924 INFO [92]#011train-auc:0.918158#011validation-auc:0.909688\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:44,051 INFO [93]#011train-auc:0.918437#011validation-auc:0.909852\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:48,950 INFO [94]#011train-auc:0.918592#011validation-auc:0.909931\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:53,989 INFO [95]#011train-auc:0.918794#011validation-auc:0.910082\u001b[0m\n",
      "\u001b[34m2020-07-15 21:50:58,856 INFO [96]#011train-auc:0.918914#011validation-auc:0.910156\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:03,948 INFO [97]#011train-auc:0.919146#011validation-auc:0.910312\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:08,916 INFO [98]#011train-auc:0.919253#011validation-auc:0.910398\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:13,961 INFO [99]#011train-auc:0.919577#011validation-auc:0.910621\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:14,161 INFO Finished training\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:14,166 INFO Finished training\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:14,166 INFO Finished training\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:14,167 INFO Finished training\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:14,168 INFO Finished training\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:14,169 INFO @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m2020-07-15 21:51:14,169 INFO @tracker 528.757761955 secs between node start and job finish\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[2020-07-15:21:52:21:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "\u001b[32m[2020-07-15:21:52:24:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "\u001b[33m[2020-07-15:21:52:54:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "\n",
      "2020-07-15 21:53:11 Uploading - Uploading generated training model\n",
      "2020-07-15 21:53:11 Completed - Training job completed\n",
      "\u001b[36m[2020-07-15:21:52:55:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "Training seconds: 4220\n",
      "Billable seconds: 4220\n"
     ]
    }
   ],
   "source": [
    "xgb_model_1 = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=5, \n",
    "                                    train_instance_type='ml.m4.4xlarge',\n",
    "                                    output_path='s3://{}/{}/{}'.format(BUCKET, MODEL_PREFIX, 'baseline'),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb_model_1.set_hyperparameters(\n",
    "                        eval_metric='auc'\n",
    "                        , alpha=1.218487609\n",
    "                        , eta=0.225242353\n",
    "                        , max_depth=10\n",
    "                        , min_child_weight=2.284773815\n",
    "                        , num_round=100\n",
    "                        , objective='binary:logistic'\n",
    "                        , rate_drop=0.3\n",
    "                        , tweedie_variance_power=1.4\n",
    "                        )\n",
    "\n",
    "xgb_model_1.fit({'train': s3_input_train, 'validation': s3_input_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Hyperparameter Tuning Job 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Hyperparameter Tuning Job 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Hyperparameter Tuning Job 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_transform(model, s3_data_path, dataset_type=\"train\", bucket=BUCKET, prefix=INFERENCE_PREFIX):\n",
    "    model_transformer = model.transformer(instance_count=2,\n",
    "                                  instance_type='ml.m4.xlarge',\n",
    "                                  strategy='MultiRecord',\n",
    "                                  assemble_with='Line',\n",
    "                                  output_path='s3://{}/{}/transform/{}'.format(bucket, prefix, dataset_type)\n",
    "                                  , accept=\"text/csv\")\n",
    "\n",
    "    return model_transformer.transform(data=s3_data_path, content_type='text/csv', split_type='Line', input_filter='$[1:]', join_source='Input', output_filter='$[0,-1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:Using already existing model: xgboost-2020-07-15-21-36-12-343\n"
     ]
    }
   ],
   "source": [
    "batch_transform(model=xgb_model_1, s3_data_path=VAL_DATA_URL, dataset_type=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:Using already existing model: xgboost-2020-07-15-21-36-12-343\n"
     ]
    }
   ],
   "source": [
    "batch_transform(model=xgb_model_1, s3_data_path=TEST_DATA_URL, dataset_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://datascience-hbo-users/users/sk/FT_propensity/7_day/inference/transform/val/val.csv.out'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch_output_file_name='s3://{}/{}/transform/val/{}.out'.format(BUCKET, INFERENCE_PREFIX, val_file_name)\n",
    "\n",
    "val_batch_output_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://datascience-hbo-users/users/sk/FT_propensity/7_day/inference/transform/test/test.csv.out'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch_output_file_name='s3://{}/{}/transform/test/{}.out'.format(BUCKET, INFERENCE_PREFIX, test_file_name)\n",
    "\n",
    "test_batch_output_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>PROBABILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.088643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.806418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.919064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.829879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTUAL  PROBABILITY\n",
       "0       0     0.088643\n",
       "1       0     0.032327\n",
       "2       1     0.806418\n",
       "3       1     0.919064\n",
       "4       1     0.829879"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_batch_results_s3=pd.read_csv(val_batch_output_file_name, header=None, names=[\"ACTUAL\", \"PROBABILITY\"])\n",
    "\n",
    "df_val_batch_results_s3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616006, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_batch_results_s3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>PROBABILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.875091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.768698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.775610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.931324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.521629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTUAL  PROBABILITY\n",
       "0       1     0.875091\n",
       "1       1     0.768698\n",
       "2       1     0.775610\n",
       "3       1     0.931324\n",
       "4       1     0.521629"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_batch_results_s3=pd.read_csv(test_batch_output_file_name, header=None, names=[\"ACTUAL\", \"PROBABILITY\"])\n",
    "\n",
    "df_test_batch_results_s3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_auc=roc_auc_score(df_val_batch_results_s3[\"ACTUAL\"],df_val_batch_results_s3[\"PROBABILITY\"]) \n",
    "test_batch_auc=roc_auc_score(df_test_batch_results_s3[\"ACTUAL\"],df_test_batch_results_s3[\"PROBABILITY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9106199423653188"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111673832627701"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    0.142858\n",
       "6    0.142858\n",
       "5    0.142858\n",
       "4    0.142858\n",
       "2    0.142858\n",
       "3    0.142856\n",
       "1    0.142856\n",
       "Name: PERIOD_RANK, dtype: float64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_side_info_s3.PERIOD_RANK.value_counts()/df_test_side_info_s3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_side_info_s3[[\"ACTUAL\"]]=df_test_batch_results_s3[[\"ACTUAL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIOD_RANK</th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>COUNT_UUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>55482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>55482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>42297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>55482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>42297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>55482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>42297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>55482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PERIOD_RANK  ACTUAL  COUNT_UUID\n",
       "0             1       0       42296\n",
       "1             1       1       55482\n",
       "2             2       0       42297\n",
       "3             2       1       55482\n",
       "4             3       0       42296\n",
       "5             3       1       55482\n",
       "6             4       0       42297\n",
       "7             4       1       55482\n",
       "8             5       0       42297\n",
       "9             5       1       55482\n",
       "10            6       0       42297\n",
       "11            6       1       55482\n",
       "12            7       0       42297\n",
       "13            7       1       55482"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_side_info_s3.groupby(by=[\"PERIOD_RANK\", \"ACTUAL\"]).size().reset_index().rename(columns={0:'COUNT_UUID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_batch_results_s3[[\"FT_SEGMENT\"]]=df_test_side_info_s3[[\"FT_SEGMENT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>PROBABILITY</th>\n",
       "      <th>FT_SEGMENT</th>\n",
       "      <th>PREDICTED</th>\n",
       "      <th>COUNT_FT_SEGMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.875091</td>\n",
       "      <td>04: Hooked &amp; Ongoing</td>\n",
       "      <td>1</td>\n",
       "      <td>16172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>01: Friends &amp; BBT Fan</td>\n",
       "      <td>1</td>\n",
       "      <td>42499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>12: Never Stream</td>\n",
       "      <td>1</td>\n",
       "      <td>173851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.931324</td>\n",
       "      <td>05: Hooked On Library</td>\n",
       "      <td>1</td>\n",
       "      <td>79133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.521629</td>\n",
       "      <td>09: Mobile First</td>\n",
       "      <td>1</td>\n",
       "      <td>66415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTUAL  PROBABILITY             FT_SEGMENT  PREDICTED  COUNT_FT_SEGMENT\n",
       "0       1     0.875091   04: Hooked & Ongoing          1             16172\n",
       "1       1     0.768698  01: Friends & BBT Fan          1             42499\n",
       "2       1     0.775610       12: Never Stream          1            173851\n",
       "3       1     0.931324  05: Hooked On Library          1             79133\n",
       "4       1     0.521629       09: Mobile First          1             66415"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_batch_results_s3_step_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_test_batch_results_s3.ACTUAL.isnull().sum()==0\n",
    "assert df_test_batch_results_s3.PROBABILITY.isnull().sum()==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the optimal threshold using AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD=0.5\n",
    "\n",
    "test_pred=np.where(df_test_batch_results_s3[[\"PROBABILITY\"]] > THRESHOLD, 1, 0)\n",
    "\n",
    "df_test_batch_results_s3[\"PREDICTED\"]=test_pred\n",
    "\n",
    "assert df_test_batch_results_s3.PREDICTED.isnull().sum()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>PROBABILITY</th>\n",
       "      <th>FT_SEGMENT</th>\n",
       "      <th>PREDICTED</th>\n",
       "      <th>COUNT_FT_SEGMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.875091</td>\n",
       "      <td>04: Hooked &amp; Ongoing</td>\n",
       "      <td>1</td>\n",
       "      <td>16172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>01: Friends &amp; BBT Fan</td>\n",
       "      <td>1</td>\n",
       "      <td>42499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>12: Never Stream</td>\n",
       "      <td>1</td>\n",
       "      <td>173851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.931324</td>\n",
       "      <td>05: Hooked On Library</td>\n",
       "      <td>1</td>\n",
       "      <td>79133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.521629</td>\n",
       "      <td>09: Mobile First</td>\n",
       "      <td>1</td>\n",
       "      <td>66415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTUAL  PROBABILITY             FT_SEGMENT  PREDICTED  COUNT_FT_SEGMENT\n",
       "0       1     0.875091   04: Hooked & Ongoing          1             16172\n",
       "1       1     0.768698  01: Friends & BBT Fan          1             42499\n",
       "2       1     0.775610       12: Never Stream          1            173851\n",
       "3       1     0.931324  05: Hooked On Library          1             79133\n",
       "4       1     0.521629       09: Mobile First          1             66415"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_batch_results_s3_step_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred=np.where(df_val_batch_results_s3[[\"PROBABILITY\"]] > THRESHOLD, 1, 0)\n",
    "\n",
    "df_val_batch_results_s3[\"PREDICTED\"]=val_pred\n",
    "\n",
    "assert df_val_batch_results_s3.PREDICTED.isnull().sum()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(mtx):\n",
    "    sn.set(font_scale=1.4) \n",
    "    sn.heatmap(pd.DataFrame(mtx), annot=True, annot_kws={\"size\": 12}, fmt='g') \n",
    "    plt.show() \n",
    "\n",
    "\n",
    "def plot_auc(train_labels, preds_train_xgb, val_labels, preds_val_xgb, test_labels, preds_test_xgb):\n",
    "    print(\"Training AUC\", roc_auc_score(train_labels, preds_train_xgb)) \n",
    "    print(\"Test AUC\", roc_auc_score(test_labels, preds_test_xgb) )\n",
    "    print(\"Validation AUC\", roc_auc_score(val_labels, preds_val_xgb) )\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(val_labels, preds_val_xgb)\n",
    "    roc_auc = auc(fpr, tpr) \n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % (roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.set_ylim([thresholds[-1],thresholds[0]])\n",
    "    ax2.set_xlim([fpr[0],fpr[-1]])\n",
    "    print(plt.figure())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_auc=roc_auc_score(df_train_predictions[\"ACTUAL\"], df_train_predictions[\"PROBABILITY\"])\n",
    "val_batch_auc=roc_auc_score(df_val_batch_results_s3[\"ACTUAL\"],df_val_batch_results_s3[\"PROBABILITY\"]) \n",
    "test_batch_auc=roc_auc_score(df_test_batch_results_s3[\"ACTUAL\"],df_test_batch_results_s3[\"PROBABILITY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9106199423653188"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111673832627701"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classification_report=classification_report(df_train_predictions[\"ACTUAL\"]\n",
    "#                                           , df_train_predictions[\"PREDICTED\"])\n",
    "\n",
    "val_classification_report=classification_report(df_val_batch_results_s3[\"ACTUAL\"]\n",
    "                                          , df_val_batch_results_s3[\"PREDICTED\"])\n",
    "\n",
    "test_classification_report=classification_report(df_test_batch_results_s3[\"ACTUAL\"]\n",
    "                                          , df_test_batch_results_s3[\"PREDICTED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80    266469\n",
      "           1       0.82      0.93      0.87    349537\n",
      "\n",
      "    accuracy                           0.84    616006\n",
      "   macro avg       0.85      0.83      0.84    616006\n",
      "weighted avg       0.85      0.84      0.84    616006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(val_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80    296077\n",
      "           1       0.82      0.93      0.87    388374\n",
      "\n",
      "    accuracy                           0.85    684451\n",
      "   macro avg       0.85      0.83      0.84    684451\n",
      "weighted avg       0.85      0.85      0.84    684451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_accuracy_score=accuracy_score(df_train_predictions[\"ACTUAL\"]\n",
    "#                                           , df_train_predictions[\"PREDICTED\"])\n",
    "\n",
    "val_accuracy_score=accuracy_score(df_val_batch_results_s3[\"ACTUAL\"]\n",
    "                                          , df_val_batch_results_s3[\"PREDICTED\"])\n",
    "\n",
    "test_accuracy_score=accuracy_score(df_test_batch_results_s3[\"ACTUAL\"]\n",
    "                                          , df_test_batch_results_s3[\"PREDICTED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444057363077633"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8451035939753174"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_confusion_matrix=confusion_matrix(df_train_predictions[\"ACTUAL\"]\n",
    "#                                           , df_train_predictions[\"PREDICTED\"])\n",
    "\n",
    "# val_confusion_matrix=confusion_matrix(df_val_predictions[\"ACTUAL\"]\n",
    "#                                           , df_val_predictions[\"PREDICTED\"])\n",
    "\n",
    "test_confusion_matrix=confusion_matrix(df_test_batch_results_s3[\"ACTUAL\"]\n",
    "                                          , df_test_batch_results_s3[\"PREDICTED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[217117,  78960],\n",
       "       [ 27059, 361315]])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.  Segment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FT_SEGMENT</th>\n",
       "      <th>COUNT_FT_SEGMENT</th>\n",
       "      <th>BASE_MODEL_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01: Friends &amp; BBT Fan</td>\n",
       "      <td>42499</td>\n",
       "      <td>0.895950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02: Talk Show &amp; News Fan</td>\n",
       "      <td>9790</td>\n",
       "      <td>0.892646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03: Series Viewer</td>\n",
       "      <td>65403</td>\n",
       "      <td>0.877529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04: Hooked &amp; Ongoing</td>\n",
       "      <td>16172</td>\n",
       "      <td>0.880720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05: Hooked On Library</td>\n",
       "      <td>79133</td>\n",
       "      <td>0.875160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06: Series Dabbler</td>\n",
       "      <td>38691</td>\n",
       "      <td>0.879145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07: All Caught Up</td>\n",
       "      <td>33872</td>\n",
       "      <td>0.880019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08: Series Abandoner</td>\n",
       "      <td>35706</td>\n",
       "      <td>0.838122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09: Mobile First</td>\n",
       "      <td>66415</td>\n",
       "      <td>0.805074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10: Movie Exclusive</td>\n",
       "      <td>97978</td>\n",
       "      <td>0.839811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11: Special Interest</td>\n",
       "      <td>24939</td>\n",
       "      <td>0.826617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12: Never Stream</td>\n",
       "      <td>173851</td>\n",
       "      <td>0.808785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13: Overall</td>\n",
       "      <td>684449</td>\n",
       "      <td>0.845104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FT_SEGMENT  COUNT_FT_SEGMENT  BASE_MODEL_ACC\n",
       "0      01: Friends & BBT Fan             42499        0.895950\n",
       "1   02: Talk Show & News Fan              9790        0.892646\n",
       "2          03: Series Viewer             65403        0.877529\n",
       "3       04: Hooked & Ongoing             16172        0.880720\n",
       "4      05: Hooked On Library             79133        0.875160\n",
       "5         06: Series Dabbler             38691        0.879145\n",
       "6          07: All Caught Up             33872        0.880019\n",
       "7       08: Series Abandoner             35706        0.838122\n",
       "8           09: Mobile First             66415        0.805074\n",
       "9        10: Movie Exclusive             97978        0.839811\n",
       "10      11: Special Interest             24939        0.826617\n",
       "11          12: Never Stream            173851        0.808785\n",
       "12               13: Overall            684449        0.845104"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_batch_results_s3=df_test_batch_results_s3[df_test_batch_results_s3.FT_SEGMENT!=\"missing\"]\n",
    "\n",
    "df_segment=df_test_batch_results_s3.groupby(SEGMENT_COL).agg({SEGMENT_COL:[\"count\"]}).reset_index().rename(columns={\"count\":f\"COUNT_{SEGMENT_COL}\"})\n",
    "df_segment.columns=df_segment.columns.values[1]\n",
    "\n",
    "df_segment.sort_values(SEGMENT_COL, inplace=True)\n",
    "\n",
    "#df_test_batch_results_s3[SEGMENT_COL]=df_test_batch_results_s3[SEGMENT_COL].apply(lambda x : x.split(\":\")[1])\n",
    "\n",
    "df_test_batch_results_s3_step_1=df_test_batch_results_s3.merge(df_segment, on=SEGMENT_COL, how=\"left\")\n",
    "\n",
    "df_test_batch_results_s3_model_1=df_test_batch_results_s3_step_1[[\"ACTUAL\", SEGMENT_COL, f\"COUNT_{SEGMENT_COL}\", \"PREDICTED\", \"PROBABILITY\"]]\n",
    "\n",
    "col_names=[\"ACTUAL\", SEGMENT_COL, f\"COUNT_{SEGMENT_COL}\", \"PREDICTED\", \"PROBABILITY\"]\n",
    "df_test_batch_results_s3_model_1.columns=col_names\n",
    "\n",
    "def report_aggregate_accuracy(data):\n",
    "    return data.groupby(SEGMENT_COL).apply(lambda group: accuracy_score(group.ACTUAL, group.PREDICTED)).reset_index().rename(columns={0:\"ACCURACY\"})\n",
    "\n",
    "df_acc_result_model_1=report_aggregate_accuracy(df_test_batch_results_s3_model_1)\n",
    "\n",
    "df_acc_result_model_1.columns=[SEGMENT_COL,\"BASE_MODEL_ACC\"]\n",
    "\n",
    "df_test_acc_final=df_segment.merge(df_acc_result_model_1, on=SEGMENT_COL, how=\"left\")\n",
    "\n",
    "\n",
    "# test_accuracy_score_model_1=accuracy_score(df_test_batch_results_s3[\"ACTUAL\"]\n",
    "#                                           , df_test_batch_results_s3[\"PREDICTED\"])\n",
    "\n",
    "df_test_acc_final.loc[len(df_test_acc_final)] = [\"13: Overall\"\n",
    "                                                  , df_test_batch_results_s3.shape[0]\n",
    "                                                  , test_accuracy_score\n",
    "                                                ]\n",
    "df_test_acc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "TIME_STR = time.strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FILE_NAME=f\"unbalanced_data_result_{TIME_STR}.csv\"\n",
    "df_test_acc_final.to_csv(RESULT_FILE_NAME, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12: Never Stream            173851\n",
       "10: Movie Exclusive          97978\n",
       "05: Hooked On Library        79133\n",
       "09: Mobile First             66415\n",
       "03: Series Viewer            65403\n",
       "01: Friends & BBT Fan        42499\n",
       "06: Series Dabbler           38691\n",
       "08: Series Abandoner         35706\n",
       "07: All Caught Up            33872\n",
       "11: Special Interest         24939\n",
       "04: Hooked & Ongoing         16172\n",
       "02: Talk Show & News Fan      9790\n",
       "Name: FT_SEGMENT, dtype: int64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_batch_results_s3.FT_SEGMENT.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score_with_value_error_handler(y_true, y_pred):\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>FT_SEGMENT</th>\n",
       "      <th>COUNT_FT_SEGMENT</th>\n",
       "      <th>PREDICTED</th>\n",
       "      <th>PROBABILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>04: Hooked &amp; Ongoing</td>\n",
       "      <td>16172</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>01: Friends &amp; BBT Fan</td>\n",
       "      <td>42499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12: Never Stream</td>\n",
       "      <td>173851</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>05: Hooked On Library</td>\n",
       "      <td>79133</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>09: Mobile First</td>\n",
       "      <td>66415</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTUAL             FT_SEGMENT  COUNT_FT_SEGMENT  PREDICTED  PROBABILITY\n",
       "0       1   04: Hooked & Ongoing             16172          1     0.875091\n",
       "1       1  01: Friends & BBT Fan             42499          1     0.768698\n",
       "2       1       12: Never Stream            173851          1     0.775610\n",
       "3       1  05: Hooked On Library             79133          1     0.931324\n",
       "4       1       09: Mobile First             66415          1     0.521629"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_batch_results_s3_model_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FT_SEGMENT</th>\n",
       "      <th>COUNT_FT_SEGMENT</th>\n",
       "      <th>BASE_MODEL_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01: Friends &amp; BBT Fan</td>\n",
       "      <td>42499</td>\n",
       "      <td>0.911798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02: Talk Show &amp; News Fan</td>\n",
       "      <td>9790</td>\n",
       "      <td>0.937311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03: Series Viewer</td>\n",
       "      <td>65403</td>\n",
       "      <td>0.902559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04: Hooked &amp; Ongoing</td>\n",
       "      <td>16172</td>\n",
       "      <td>0.921688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05: Hooked On Library</td>\n",
       "      <td>79133</td>\n",
       "      <td>0.901649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06: Series Dabbler</td>\n",
       "      <td>38691</td>\n",
       "      <td>0.918221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07: All Caught Up</td>\n",
       "      <td>33872</td>\n",
       "      <td>0.932060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08: Series Abandoner</td>\n",
       "      <td>35706</td>\n",
       "      <td>0.910560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09: Mobile First</td>\n",
       "      <td>66415</td>\n",
       "      <td>0.886274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10: Movie Exclusive</td>\n",
       "      <td>97978</td>\n",
       "      <td>0.908077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11: Special Interest</td>\n",
       "      <td>24939</td>\n",
       "      <td>0.903254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12: Never Stream</td>\n",
       "      <td>173851</td>\n",
       "      <td>0.889290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FT_SEGMENT  COUNT_FT_SEGMENT  BASE_MODEL_AUC\n",
       "0      01: Friends & BBT Fan             42499        0.911798\n",
       "1   02: Talk Show & News Fan              9790        0.937311\n",
       "2          03: Series Viewer             65403        0.902559\n",
       "3       04: Hooked & Ongoing             16172        0.921688\n",
       "4      05: Hooked On Library             79133        0.901649\n",
       "5         06: Series Dabbler             38691        0.918221\n",
       "6          07: All Caught Up             33872        0.932060\n",
       "7       08: Series Abandoner             35706        0.910560\n",
       "8           09: Mobile First             66415        0.886274\n",
       "9        10: Movie Exclusive             97978        0.908077\n",
       "10      11: Special Interest             24939        0.903254\n",
       "11          12: Never Stream            173851        0.889290"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def report_aggregate_roc_auc(data):\n",
    "    return data.groupby(SEGMENT_COL).apply(lambda group: roc_auc_score_with_value_error_handler(group.ACTUAL, group.PROBABILITY)).reset_index().rename(columns={0:\"AUC\"})\n",
    "\n",
    "df_auc_result_model_1=report_aggregate_roc_auc(df_test_batch_results_s3_model_1)\n",
    "\n",
    "df_auc_result_model_1.columns=[SEGMENT_COL,\"BASE_MODEL_AUC\"]\n",
    "\n",
    "df_test_auc_final=df_segment.merge(df_auc_result_model_1, on=SEGMENT_COL, how=\"left\")\n",
    "df_test_auc_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Accuracy on balanced test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_test_data_set(data, random_state=RANDOM_STATE):\n",
    "    df_majority=data[data.ACTUAL==1]\n",
    "    df_minority=data[data.ACTUAL==0]\n",
    "    num_minority_class=df_minority.shape[0]\n",
    "    df_majority_frac=df_majority.sample(num_minority_class, random_state=random_state)\n",
    "    df_balanced_test=df_minority.append(df_majority_frac)\n",
    "    return df_balanced_test\n",
    "    \n",
    "df_balanced_test_s3=create_balanced_test_data_set(df_test_batch_results_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>PROBABILITY</th>\n",
       "      <th>FT_SEGMENT</th>\n",
       "      <th>PREDICTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>09: Mobile First</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.759041</td>\n",
       "      <td>05: Hooked On Library</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>09: Mobile First</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.263935</td>\n",
       "      <td>12: Never Stream</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.128843</td>\n",
       "      <td>01: Friends &amp; BBT Fan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ACTUAL  PROBABILITY             FT_SEGMENT  PREDICTED\n",
       "5        0     0.004202       09: Mobile First          0\n",
       "7        0     0.759041  05: Hooked On Library          1\n",
       "10       0     0.013879       09: Mobile First          0\n",
       "14       0     0.263935       12: Never Stream          0\n",
       "17       0     0.128843  01: Friends & BBT Fan          0"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_test_s3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    388373\n",
       "0    296076\n",
       "Name: ACTUAL, dtype: int64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_batch_results_s3.ACTUAL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    296076\n",
       "0    296076\n",
       "Name: ACTUAL, dtype: int64"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_test_s3.ACTUAL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12: Never Stream            0.254001\n",
       "10: Movie Exclusive         0.143149\n",
       "05: Hooked On Library       0.115616\n",
       "09: Mobile First            0.097034\n",
       "03: Series Viewer           0.095556\n",
       "01: Friends & BBT Fan       0.062092\n",
       "06: Series Dabbler          0.056529\n",
       "08: Series Abandoner        0.052168\n",
       "07: All Caught Up           0.049488\n",
       "11: Special Interest        0.036437\n",
       "04: Hooked & Ongoing        0.023628\n",
       "02: Talk Show & News Fan    0.014303\n",
       "Name: FT_SEGMENT, dtype: float64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_batch_results_s3.FT_SEGMENT.value_counts()/df_test_batch_results_s3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12: Never Stream            0.226346\n",
       "10: Movie Exclusive         0.125130\n",
       "05: Hooked On Library       0.096412\n",
       "09: Mobile First            0.085818\n",
       "03: Series Viewer           0.078859\n",
       "01: Friends & BBT Fan       0.051466\n",
       "06: Series Dabbler          0.047841\n",
       "08: Series Abandoner        0.045678\n",
       "07: All Caught Up           0.042804\n",
       "11: Special Interest        0.033005\n",
       "04: Hooked & Ongoing        0.019931\n",
       "02: Talk Show & News Fan    0.011862\n",
       "Name: FT_SEGMENT, dtype: float64"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_test_s3.FT_SEGMENT.value_counts()/df_test_batch_results_s3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FT_SEGMENT</th>\n",
       "      <th>COUNT_FT_SEGMENT</th>\n",
       "      <th>BASE_MODEL_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01: Friends &amp; BBT Fan</td>\n",
       "      <td>35203</td>\n",
       "      <td>0.879726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02: Talk Show &amp; News Fan</td>\n",
       "      <td>8112</td>\n",
       "      <td>0.876849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03: Series Viewer</td>\n",
       "      <td>53960</td>\n",
       "      <td>0.857802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04: Hooked &amp; Ongoing</td>\n",
       "      <td>13599</td>\n",
       "      <td>0.862931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05: Hooked On Library</td>\n",
       "      <td>66011</td>\n",
       "      <td>0.856297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06: Series Dabbler</td>\n",
       "      <td>32748</td>\n",
       "      <td>0.863198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07: All Caught Up</td>\n",
       "      <td>29260</td>\n",
       "      <td>0.867157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08: Series Abandoner</td>\n",
       "      <td>31313</td>\n",
       "      <td>0.826462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09: Mobile First</td>\n",
       "      <td>58759</td>\n",
       "      <td>0.790347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10: Movie Exclusive</td>\n",
       "      <td>85663</td>\n",
       "      <td>0.827183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11: Special Interest</td>\n",
       "      <td>22625</td>\n",
       "      <td>0.825282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12: Never Stream</td>\n",
       "      <td>154899</td>\n",
       "      <td>0.802833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>missing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13: Overall</td>\n",
       "      <td>592154</td>\n",
       "      <td>0.831676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FT_SEGMENT  COUNT_FT_SEGMENT  BASE_MODEL_ACC\n",
       "0      01: Friends & BBT Fan             35203        0.879726\n",
       "1   02: Talk Show & News Fan              8112        0.876849\n",
       "2          03: Series Viewer             53960        0.857802\n",
       "3       04: Hooked & Ongoing             13599        0.862931\n",
       "4      05: Hooked On Library             66011        0.856297\n",
       "5         06: Series Dabbler             32748        0.863198\n",
       "6          07: All Caught Up             29260        0.867157\n",
       "7       08: Series Abandoner             31313        0.826462\n",
       "8           09: Mobile First             58759        0.790347\n",
       "9        10: Movie Exclusive             85663        0.827183\n",
       "10      11: Special Interest             22625        0.825282\n",
       "11          12: Never Stream            154899        0.802833\n",
       "12                   missing                 2        1.000000\n",
       "13               13: Overall            592154        0.831676"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_segment=df_balanced_test_s3.groupby(SEGMENT_COL).agg({SEGMENT_COL:[\"count\"]}).reset_index().rename(columns={\"count\":f\"COUNT_{SEGMENT_COL}\"})\n",
    "df_segment.columns=df_segment.columns.values[1]\n",
    "\n",
    "df_segment.sort_values(SEGMENT_COL, inplace=True)\n",
    "\n",
    "# df_balanced_test_s3[SEGMENT_COL]=df_balanced_test_s3[SEGMENT_COL].apply(lambda x : x.split(\":\")[1])\n",
    "\n",
    "df_balanced_test_s3=df_balanced_test_s3.merge(df_segment, on=SEGMENT_COL, how=\"left\")\n",
    "\n",
    "df_balanced_test_s3_model_1=df_balanced_test_s3[[\"ACTUAL\", SEGMENT_COL, f\"COUNT_{SEGMENT_COL}\", \"PREDICTED\"]]\n",
    "\n",
    "col_names=[\"ACTUAL\", SEGMENT_COL, f\"COUNT_{SEGMENT_COL}\", \"PREDICTED\"]\n",
    "df_balanced_test_s3_model_1.columns=col_names\n",
    "\n",
    "def report_aggregate_accuracy(data):\n",
    "    return data.groupby(SEGMENT_COL).apply(lambda group: accuracy_score(group.ACTUAL, group.PREDICTED)).reset_index().rename(columns={0:\"ACCURACY\"})\n",
    "\n",
    "df_acc_result_model_1=report_aggregate_accuracy(df_balanced_test_s3_model_1)\n",
    "\n",
    "df_acc_result_model_1.columns=[SEGMENT_COL,\"BASE_MODEL_ACC\"]\n",
    "\n",
    "df_balanced_test_acc_final=df_segment.merge(df_acc_result_model_1, on=SEGMENT_COL, how=\"left\")\n",
    "\n",
    "balanced_val_accuracy_score_model_1=accuracy_score(df_balanced_test_s3[\"ACTUAL\"]\n",
    "                                          , df_balanced_test_s3[\"PREDICTED\"])\n",
    "\n",
    "df_balanced_test_acc_final.loc[len(df_balanced_test_acc_final)] = [\"13: Overall\"\n",
    "                                                  , df_balanced_test_s3.shape[0]\n",
    "                                                  , balanced_val_accuracy_score_model_1\n",
    "                                                ]\n",
    "df_balanced_test_acc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "BALANCED_RESULT_FILE_NAME=f\"balanced_data_result_{TIME_STR}.csv\"\n",
    "df_balanced_test_acc_final.to_csv(BALANCED_RESULT_FILE_NAME, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316755438619008"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
